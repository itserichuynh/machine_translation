{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "172eeadc-b24d-4a95-9118-b356b13ad0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ba4f8b-5a60-418e-a3fe-cb6fff89d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import string\n",
    "import re\n",
    "from pickle import dump, load\n",
    "from unicodedata import normalize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e4edcc-13b1-493f-b6aa-5fb87035ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "import torchtext\n",
    "import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f0f0b74-2d80-436d-923b-4018667e5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16154ead-44d4-40bc-945c-effd6e5366d2",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6485e08a-e68b-47ee-84c7-6f21d4095b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36e81dcb-2772-446c-a5c0-801f25209986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def readData(lang1, lang2):\n",
    "#     print(\"Reading lines...\")\n",
    "\n",
    "#     # Read the file and split into lines\n",
    "#     lines = open('../data/wiki/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "#         read().strip().split('\\n')\n",
    "\n",
    "#     # Split every line into pairs and normalize\n",
    "#     pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "#     # Reverse pairs, make Lang instances\n",
    "#     # if reverse:\n",
    "#     #     pairs = [list(reversed(p)) for p in pairs]\n",
    "#     #     input_lang = Lang(lang2)\n",
    "#     #     output_lang = Lang(lang1)\n",
    "#     # else:\n",
    "#     #     input_lang = Lang(lang1)\n",
    "#     #     output_lang = Lang(lang2)\n",
    "\n",
    "#     data = [{lang1: pairs[0], lang2: pairs[1]}for pair in pairs]\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7f7890a-2ff6-4c2a-860a-adbbd2898325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = readData('en', 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06e7c943-7478-4919-a8a3-6d34eeddf77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "def tmx_to_tabbed_txt(tmx_file, output_file):\n",
    "    \"\"\"Extracts English and Hawaiian translations from a TMX file and saves them as tab-separated pairs.\"\"\"\n",
    "    \n",
    "    # Define the XML namespace for `xml:lang`\n",
    "    namespaces = {'xml': 'http://www.w3.org/XML/1998/namespace'}\n",
    "    \n",
    "    # Parse the TMX file\n",
    "    xml_tree = etree.parse(tmx_file)\n",
    "    trans_units = xml_tree.findall(\".//tu\")\n",
    "\n",
    "    pairs = []\n",
    "    \n",
    "    # Open the output file for writing\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        # Iterate over each translation unit\n",
    "        for trans_unit in trans_units:\n",
    "            pair = []\n",
    "            source_text = trans_unit.find(\".//tuv[@xml:lang='en']/seg\", namespaces)\n",
    "            target_text = trans_unit.find(\".//tuv[@xml:lang='fr']/seg\", namespaces)\n",
    "\n",
    "            # Write the tab-separated pair if both texts are available\n",
    "            if source_text is not None and target_text is not None and source_text.text and target_text.text:\n",
    "                out_file.write(f\"{source_text.text}\\t{target_text.text}\\n\")\n",
    "                pair.append(source_text.text)\n",
    "                pair.append(target_text.text)\n",
    "                pairs.append(pair)\n",
    "\n",
    "    return pairs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tmx_file = \"../data/wiki/en-fr.tmx\"\n",
    "    output_file = \"../data/wiki/en-fr.txt\"\n",
    "    pairs = tmx_to_tabbed_txt(tmx_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f472bebe-87c1-4a0a-aaaa-27bc42bbb0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [[normalizeString(sentence) for sentence in pair] for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "461416f7-155a-4cbf-b848-96dfd489af22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1365840"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "203040e3-3a5b-451b-b07e-0d84504d3d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133481"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_pairs = [pair for pair in pairs if (len(pair[0]) > 0 and len(pair[0]) <= 40) and (len(pair[0]) > 0 and len(pair[0]) <= 40)]\n",
    "len(cleaned_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4e709da-8198-4163-bf0c-a38896851120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the same amount of data with tatoeba\n",
    "# tatoeba_size = 135842\n",
    "# random.seed(1234)\n",
    "# start_index = random.randint(0, len(pairs) - tatoeba_size)\n",
    "# small_pairs = pairs[start_index:start_index + tatoeba_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ada2934-9af3-4fc8-9e21-09dc8d78940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(small_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "936bf70b-cd43-4c66-9fba-03f8407577ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34904996-cf47-4425-b200-aa0b3f1ec42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'en': 'third stream', 'fr': 'le third stream'},\n",
       " {'en': 'gil evans influence', 'fr': 'l influence de gil evans'},\n",
       " {'en': 'the horn in the spotlight', 'fr': 'le cor sous les projecteurs'},\n",
       " {'en': 'contemporary horn in jazz', 'fr': 'le cor dans le jazz contemporain'},\n",
       " {'en': 'horn in jazz', 'fr': 'utilisateur djiboun le cor dans le jazz'},\n",
       " {'en': 'murder of jewish civil rights activists',\n",
       "  'fr': 'meurtre de militants juifs des droits civiques'},\n",
       " {'en': 'questioning the golden age', 'fr': 'interrogations sur l age d or'},\n",
       " {'en': 'the problem was the condescending tone',\n",
       "  'fr': 'le probleme etait le ton condescendant'},\n",
       " {'en': 'edwards brent hayes', 'fr': 'note on the text'},\n",
       " {'en': 'note on the text the souls of black folk',\n",
       "  'fr': 'the souls of black folk'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [{'en': pair[0], 'fr': pair[1]} for pair in cleaned_pairs]\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07b1e52d-64a4-44e6-9da8-62d32a2ed289",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fc12cc8-497c-423d-8983-80f876e9a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splittng data\n",
    "n = len(data)\n",
    "n_train = int(0.8*n)\n",
    "n_val = int(0.9*n)\n",
    "\n",
    "train_data = data[:n_train]\n",
    "val_data = data[n_train:n_val]\n",
    "test_data = data[n_val:]\n",
    "\n",
    "# convert to Huggingface dataset\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "# Create the DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9979ef23-6b66-4691-9bf0-ec40bb997cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 106784\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 13348\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 13349\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1935ebe-e295-42c6-bee2-9602e920b81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'votes for women poster', 'fr': 'affiche de votes pour les femmes'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daf9b47d-9f45-40e7-96fb-fcb622490034",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "fr_nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d288c24-9e5d-41bc-8441-395eedd33361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"What a lovely day it is today!\"\n",
    "\n",
    "[token.text for token in en_nlp.tokenizer(string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05ae8750-8638-4c08-b352-4877982e4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, en_nlp, fr_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    fr_tokens = [token.text for token in fr_nlp.tokenizer(example[\"fr\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        fr_tokens = [token.lower() for token in fr_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    fr_tokens = [sos_token] + fr_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"fr_tokens\": fr_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef42e644-a5d6-4e81-abe9-a1876b552a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600873e6ecb34970a6997d0c43af06b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/106784 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191998d0a9734cbc92fa8cf88b3fc9ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13348 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f927a521087f48a0993f4568db247a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 40\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"fr_nlp\": fr_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "val_dataset = val_dataset.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_dataset = test_dataset.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ee1ab18-4420-4309-b4aa-1bf9bb494e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'votes for women poster',\n",
       " 'fr': 'affiche de votes pour les femmes',\n",
       " 'en_tokens': ['<sos>', 'votes', 'for', 'women', 'poster', '<eos>'],\n",
       " 'fr_tokens': ['<sos>',\n",
       "  'affiche',\n",
       "  'de',\n",
       "  'votes',\n",
       "  'pour',\n",
       "  'les',\n",
       "  'femmes',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b83189d-35d5-445c-8765-e16036f87535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    train_dataset[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "fr_vocab = build_vocab_from_iterator(\n",
    "    train_dataset[\"fr_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad9fd9ed-837c-4ed0-aeb6-2550a803f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', 'the', 'in', 'of', 'and', 'was', 'a']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1ee3a37-4998-48c4-a8af-133a030e8195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', 'de', 'a', 'en', 'la', 'le', 'est']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b28c4e21-22be-42fc-b36e-3c3fa5921776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5f14985-75d8-4c66-955f-3ade284de109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21225, 26484)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab), len(fr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d82ebb20-1056-41ce-8ea2-2338e59dce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == fr_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == fr_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7e9a13f-be4c-478d-8bd4-edcbfb43b94d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Token The not found and default index is not set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m en_vocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchtext/vocab/vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[token]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Token The not found and default index is not set"
     ]
    }
   ],
   "source": [
    "en_vocab['The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0672db85-316b-49cc-9965-f521cf9e2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "fr_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62037a77-2878-463d-ac24-2f9bbb808220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab['The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78749614-4afe-4d39-a200-98f2b88735fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6fc597e-9efe-456a-9818-a19c0feab279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[42, 404, 13943, 2836, 563]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "en_vocab.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7efd029a-1822-4b51-be70-68a153625bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'watching', 'crime', 'shows']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b4051b3-523e-4e0d-b3e3-778480a1fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, fr_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    fr_ids = fr_vocab.lookup_indices(example[\"fr_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"fr_ids\": fr_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2259c4c9-c1a1-47d4-a8f3-43000c1d5edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b25b0649bc745b9bf7a5e2dfb9e8181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/106784 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189faaf52624419d82a5a7857989873a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13348 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3834d029f7411aaa0a9b90e48399d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn_kwargs = {\"en_vocab\": en_vocab, \"fr_vocab\": fr_vocab}\n",
    "\n",
    "train_dataset = train_dataset.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "val_dataset = val_dataset.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_dataset = test_dataset.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0126392-63ea-48b4-a44c-b4460e95fb91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'votes for women poster',\n",
       " 'fr': 'affiche de votes pour les femmes',\n",
       " 'en_tokens': ['<sos>', 'votes', 'for', 'women', 'poster', '<eos>'],\n",
       " 'fr_tokens': ['<sos>',\n",
       "  'affiche',\n",
       "  'de',\n",
       "  'votes',\n",
       "  'pour',\n",
       "  'les',\n",
       "  'femmes',\n",
       "  '<eos>'],\n",
       " 'en_ids': [2, 2155, 23, 156, 2911, 3],\n",
       " 'fr_ids': [2, 2215, 4, 4596, 28, 14, 208, 3]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5472f0fa-ca58-49df-8225-a95feb78a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"fr_ids\"]\n",
    "\n",
    "train_dataset = train_dataset.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8a412cf-ae03-4b5e-8f91-5b19a5d82318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([   2, 2155,   23,  156, 2911,    3]),\n",
       " 'fr_ids': tensor([   2, 2215,    4, 4596,   28,   14,  208,    3]),\n",
       " 'en': 'votes for women poster',\n",
       " 'fr': 'affiche de votes pour les femmes',\n",
       " 'en_tokens': ['<sos>', 'votes', 'for', 'women', 'poster', '<eos>'],\n",
       " 'fr_tokens': ['<sos>',\n",
       "  'affiche',\n",
       "  'de',\n",
       "  'votes',\n",
       "  'pour',\n",
       "  'les',\n",
       "  'femmes',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1a6a4-9c12-4ef7-9479-fe8917f11ed4",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11a0dc84-4302-4500-9c74-78e26189e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_fr_ids = [example[\"fr_ids\"] for example in batch]\n",
    "        en_lens = [example[\"en_ids\"].shape[0] for example in batch]\n",
    "        fr_lens = [example[\"fr_ids\"].shape[0] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_fr_ids = nn.utils.rnn.pad_sequence(batch_fr_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"fr_ids\": batch_fr_ids,\n",
    "            \"en_lens\": en_lens,\n",
    "            \"fr_lens\": fr_lens\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba61c82b-6019-428a-92b6-23e775d323e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d37c284b-467d-4963-8535-8848023f4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_dataset, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(val_dataset, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_dataset, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c7382b22-5517-4dd8-96e5-b613d2736f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "15132e3e-6ec4-4ee3-98da-380436ecee87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1cb4f4cb-2793-4f88-b6ae-cdaf2b985326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "835"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bafc0aa-8ed6-4e48-bb74-c67c1c3b8f48",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2cd78b8-6e7a-4a03-b50f-db99b4b020d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_lens):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, np.array(src_lens), enforce_sorted=False, batch_first=False)\n",
    "        packed_outputs, (hidden, cell) = self.rnn(packed)\n",
    "        # outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ec6bd65-52ad-4248-8d79-1437d807b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # context = [n layers, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output = [seq length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # cell = [n layers, batch size, hidden dim]\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aadbceed-85fc-4101-925a-b8683f6ed8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, src_lens, trg, trg_lens, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src, src_lens)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        # input = [batch size]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden and previous cell states\n",
    "            # receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, hidden dim]\n",
    "            # cell = [n layers, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689f030-ac73-4f1e-b234-7c08a04c6a13",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b37c761b-ae7e-4e8c-b674-972407363db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(fr_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6e9ce29-f95b-4df3-b40e-2cea2e665fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26484, 21225)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aad77bee-231e-4a58-aff0-2e2dc55f40f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(26484, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(21225, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=21225, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6c26f1d8-c966-464c-8341-ea335be4c01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 30,458,345 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97c50989-40e5-4d91-be13-d2449961d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6977cfc-e8b5-4394-9e3a-68e3465a4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"fr_ids\"].to(device)\n",
    "        src_lens = batch[\"fr_lens\"]\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        trg_lens = batch[\"en_lens\"]\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, src_lens, trg, trg_lens, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e475dff0-21fb-489a-91ff-e81aba19719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"fr_ids\"].to(device)\n",
    "            src_lens = batch[\"fr_lens\"]\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            trg_lens = batch[\"en_lens\"]\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, src_lens, trg, trg_lens, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7c0aa914-961b-433f-814f-b9970fc12764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../models/wiki/2024-12-01' created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/10 [07:47<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 36.22 GB, other allocations: 7.82 GB, max allowed: 45.90 GB). Tried to allocate 6.55 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m val_lossi \u001b[38;5;241m=\u001b[39m []  \n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs)):\n\u001b[0;32m---> 20\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train_fn(\n\u001b[1;32m     21\u001b[0m         model,\n\u001b[1;32m     22\u001b[0m         train_data_loader,\n\u001b[1;32m     23\u001b[0m         optimizer,\n\u001b[1;32m     24\u001b[0m         criterion,\n\u001b[1;32m     25\u001b[0m         clip,\n\u001b[1;32m     26\u001b[0m         teacher_forcing_ratio,\n\u001b[1;32m     27\u001b[0m         device,\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     29\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate_fn(\n\u001b[1;32m     30\u001b[0m         model,\n\u001b[1;32m     31\u001b[0m         valid_data_loader,\n\u001b[1;32m     32\u001b[0m         criterion,\n\u001b[1;32m     33\u001b[0m         device,\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     36\u001b[0m     train_lossi\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[70], line 22\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# trg = [(trg length - 1) * batch size]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, trg)\n\u001b[0;32m---> 22\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     23\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), clip)\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    527\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[1;32m    268\u001b[0m     tensors,\n\u001b[1;32m    269\u001b[0m     grad_tensors_,\n\u001b[1;32m    270\u001b[0m     retain_graph,\n\u001b[1;32m    271\u001b[0m     create_graph,\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 36.22 GB, other allocations: 7.82 GB, max allowed: 45.90 GB). Tried to allocate 6.55 GB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "model_dir = f'../models/wiki/{date}'\n",
    "# Create the directory\n",
    "try:\n",
    "    os.mkdir(model_dir)\n",
    "    print(f\"Directory '{model_dir}' created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{model_dir}' already exists.\")\n",
    "\n",
    "train_lossi = []\n",
    "val_lossi = []  \n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "\n",
    "    train_lossi.append(train_loss)\n",
    "    val_lossi.append(valid_loss)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, f'mt_tatoeba_{train_loss:7.2f}_{valid_loss:7.2f}.pt'))\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f6d16c-254a-4943-abfa-1f80d580c977",
   "metadata": {},
   "source": [
    "### Evaluating on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b062474-122f-4ba7-ad31-40c1642d39e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.232 | Test PPL:   9.314 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(model_dir, f'mt_tatoeba.pt')))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3529853-917c-4aeb-821b-8faae4088b46",
   "metadata": {},
   "source": [
    "### BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "489816d4-d19b-4be6-89b2-a20897500f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    fr_nlp,\n",
    "    en_vocab,\n",
    "    fr_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            tokens = [token.text for token in fr_nlp.tokenizer(sentence)]\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = fr_vocab.lookup_indices(tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        src_len = [tensor.shape[0]]\n",
    "        hidden, cell = model.encoder(tensor, src_len)\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        tokens = en_vocab.lookup_tokens(inputs)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8161c3a8-c0ed-4bbf-b3bf-70eecf88d178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('laissez les mains sur le volant', 'keep your hands on the wheel')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[0][\"fr\"]\n",
    "expected_translation = test_data[0][\"en\"]\n",
    "\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e338b1c8-758b-4646-ae86-435712b72762",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    fr_nlp,\n",
    "    en_vocab,\n",
    "    fr_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3494b57c-e64a-4213-aa08-71cad83b61af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'keep', 'your', 'hands', 'clean', 'the', 'wheel', '<eos>']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95016306-2816-4098-9f88-a6cad297b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Bonjour.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "398efc9f-102f-4337-a919-d8238bc5b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    fr_nlp,\n",
    "    en_vocab,\n",
    "    fr_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5df628b6-792f-4c3c-87ad-380b19a75378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'good', 'medication', 'went', '<eos>']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ad9d7364-9992-41a7-8375-93f58eacc62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 13585/13585 [03:09<00:00, 71.51it/s]\n"
     ]
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"fr\"],\n",
    "        model,\n",
    "        en_nlp,\n",
    "        fr_nlp,\n",
    "        en_vocab,\n",
    "        fr_vocab,\n",
    "        lower,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "    )\n",
    "    for example in tqdm.tqdm(test_dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc0af41a-ae8c-4fe7-ab78-f6fecbcf8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "02c9ef00-ebe2-47f5-8acf-e92037144482",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "\n",
    "references = [[example[\"en\"]] for example in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6fbbabf8-a13b-49a2-9afa-074542db85df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('keep your hands clean the wheel', ['keep your hands on the wheel'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0], references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "33c93115-0202-4440-b2fa-ca59d3aa8c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([   2,  192,   31,  483,   39,    7, 2844,    3]),\n",
       " 'fr_ids': tensor([   2,  357,   28,  538,   66,   15, 2639,    3]),\n",
       " 'en': 'keep your hands on the wheel',\n",
       " 'fr': 'laissez les mains sur le volant',\n",
       " 'en_tokens': ['<sos>',\n",
       "  'keep',\n",
       "  'your',\n",
       "  'hands',\n",
       "  'on',\n",
       "  'the',\n",
       "  'wheel',\n",
       "  '<eos>'],\n",
       " 'fr_tokens': ['<sos>',\n",
       "  'laissez',\n",
       "  'les',\n",
       "  'mains',\n",
       "  'sur',\n",
       "  'le',\n",
       "  'volant',\n",
       "  '<eos>']}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f5b4953-269e-4b8e-93bc-f8be471edf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_fn(nlp, lower):\n",
    "    def tokenizer_fn(s):\n",
    "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        return tokens\n",
    "\n",
    "    return tokenizer_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "14f0711f-61b3-4749-88d4-82f81ba9864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8160d26c-83ec-4656-93f3-87c2b8d83605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['keep', 'your', 'hands', 'clean', 'the', 'wheel'],\n",
       " ['keep', 'your', 'hands', 'on', 'the', 'wheel'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fn(predictions[0]), tokenizer_fn(references[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d02c0669-686a-46c4-a9cd-6507e7d33036",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bleu.compute(\n",
    "    predictions=predictions, references=references, tokenizer=tokenizer_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60c7cb11-d5b8-4424-b328-e027b4c80365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.4083577307341744,\n",
       " 'precisions': [0.6633725198032276,\n",
       "  0.46059880547832355,\n",
       "  0.34380606211877757,\n",
       "  0.2647093689493026],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0024932451727697,\n",
       " 'translation_length': 91273,\n",
       " 'reference_length': 91046}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0166993f-1a2e-46ef-8f5e-549e2155def0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
