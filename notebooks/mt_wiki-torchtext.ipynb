{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172eeadc-b24d-4a95-9118-b356b13ad0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ba4f8b-5a60-418e-a3fe-cb6fff89d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import string\n",
    "import re\n",
    "from pickle import dump, load\n",
    "from unicodedata import normalize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e4edcc-13b1-493f-b6aa-5fb87035ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "import torchtext\n",
    "import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0f0b74-2d80-436d-923b-4018667e5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16154ead-44d4-40bc-945c-effd6e5366d2",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6485e08a-e68b-47ee-84c7-6f21d4095b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e81dcb-2772-446c-a5c0-801f25209986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def readData(lang1, lang2):\n",
    "#     print(\"Reading lines...\")\n",
    "\n",
    "#     # Read the file and split into lines\n",
    "#     lines = open('../data/wiki/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "#         read().strip().split('\\n')\n",
    "\n",
    "#     # Split every line into pairs and normalize\n",
    "#     pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "#     # Reverse pairs, make Lang instances\n",
    "#     # if reverse:\n",
    "#     #     pairs = [list(reversed(p)) for p in pairs]\n",
    "#     #     input_lang = Lang(lang2)\n",
    "#     #     output_lang = Lang(lang1)\n",
    "#     # else:\n",
    "#     #     input_lang = Lang(lang1)\n",
    "#     #     output_lang = Lang(lang2)\n",
    "\n",
    "#     data = [{lang1: pairs[0], lang2: pairs[1]}for pair in pairs]\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7f7890a-2ff6-4c2a-860a-adbbd2898325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = readData('en', 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e7c943-7478-4919-a8a3-6d34eeddf77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "\n",
    "def tmx_to_tabbed_txt(tmx_file, output_file):\n",
    "    \"\"\"Extracts English and Hawaiian translations from a TMX file and saves them as tab-separated pairs.\"\"\"\n",
    "    \n",
    "    # Define the XML namespace for `xml:lang`\n",
    "    namespaces = {'xml': 'http://www.w3.org/XML/1998/namespace'}\n",
    "    \n",
    "    # Parse the TMX file\n",
    "    xml_tree = etree.parse(tmx_file)\n",
    "    trans_units = xml_tree.findall(\".//tu\")\n",
    "\n",
    "    pairs = []\n",
    "    \n",
    "    # Open the output file for writing\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as out_file:\n",
    "        # Iterate over each translation unit\n",
    "        for trans_unit in trans_units:\n",
    "            pair = []\n",
    "            source_text = trans_unit.find(\".//tuv[@xml:lang='en']/seg\", namespaces)\n",
    "            target_text = trans_unit.find(\".//tuv[@xml:lang='fr']/seg\", namespaces)\n",
    "\n",
    "            # Write the tab-separated pair if both texts are available\n",
    "            if source_text is not None and target_text is not None and source_text.text and target_text.text:\n",
    "                out_file.write(f\"{source_text.text}\\t{target_text.text}\\n\")\n",
    "                pair.append(source_text.text)\n",
    "                pair.append(target_text.text)\n",
    "                pairs.append(pair)\n",
    "\n",
    "    return pairs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tmx_file = \"../data/wiki/en-fr.tmx\"\n",
    "    output_file = \"../data/wiki/en-fr.txt\"\n",
    "    pairs = tmx_to_tabbed_txt(tmx_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f472bebe-87c1-4a0a-aaaa-27bc42bbb0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [[normalizeString(sentence) for sentence in pair] for pair in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "461416f7-155a-4cbf-b848-96dfd489af22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1365840"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "203040e3-3a5b-451b-b07e-0d84504d3d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137932"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_pairs = [pair for pair in pairs if (len(pair[0]) > 0 and len(pair[0]) <= 41) and (len(pair[0]) > 0 and len(pair[0]) <= 41)]\n",
    "len(cleaned_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e709da-8198-4163-bf0c-a38896851120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the same amount of data with tatoeba\n",
    "# tatoeba_size = 135842\n",
    "# random.seed(1234)\n",
    "# start_index = random.randint(0, len(pairs) - tatoeba_size)\n",
    "# small_pairs = pairs[start_index:start_index + tatoeba_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ada2934-9af3-4fc8-9e21-09dc8d78940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(small_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936bf70b-cd43-4c66-9fba-03f8407577ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34904996-cf47-4425-b200-aa0b3f1ec42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'en': 'third stream', 'fr': 'le third stream'},\n",
       " {'en': 'gil evans influence', 'fr': 'l influence de gil evans'},\n",
       " {'en': 'the horn in the spotlight', 'fr': 'le cor sous les projecteurs'},\n",
       " {'en': 'contemporary horn in jazz', 'fr': 'le cor dans le jazz contemporain'},\n",
       " {'en': 'horn in jazz', 'fr': 'utilisateur djiboun le cor dans le jazz'},\n",
       " {'en': 'murder of jewish civil rights activists',\n",
       "  'fr': 'meurtre de militants juifs des droits civiques'},\n",
       " {'en': 'questioning the golden age', 'fr': 'interrogations sur l age d or'},\n",
       " {'en': 'the problem was the condescending tone',\n",
       "  'fr': 'le probleme etait le ton condescendant'},\n",
       " {'en': 'press of mississippi p lindemann albert s',\n",
       "  'fr': 'black jewish relations on trial leo frank and jim conley in the new south univ'},\n",
       " {'en': 'edwards brent hayes', 'fr': 'note on the text'}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [{'en': pair[0], 'fr': pair[1]} for pair in cleaned_pairs]\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07b1e52d-64a4-44e6-9da8-62d32a2ed289",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fc12cc8-497c-423d-8983-80f876e9a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splittng data\n",
    "n = len(data)\n",
    "n_train = int(0.8*n)\n",
    "n_val = int(0.9*n)\n",
    "\n",
    "train_data = data[:n_train]\n",
    "val_data = data[n_train:n_val]\n",
    "test_data = data[n_val:]\n",
    "\n",
    "# convert to Huggingface dataset\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "# Create the DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9979ef23-6b66-4691-9bf0-ec40bb997cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 110345\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 13793\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 13794\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1935ebe-e295-42c6-bee2-9602e920b81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'main personal exhibitions',\n",
       " 'fr': 'principales expositions personnelles'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "daf9b47d-9f45-40e7-96fb-fcb622490034",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "fr_nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d288c24-9e5d-41bc-8441-395eedd33361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"What a lovely day it is today!\"\n",
    "\n",
    "[token.text for token in en_nlp.tokenizer(string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05ae8750-8638-4c08-b352-4877982e4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, en_nlp, fr_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    fr_tokens = [token.text for token in fr_nlp.tokenizer(example[\"fr\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        fr_tokens = [token.lower() for token in fr_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    fr_tokens = [sos_token] + fr_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"fr_tokens\": fr_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef42e644-a5d6-4e81-abe9-a1876b552a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199a7662605f434fb6d1a8191fb3c1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945a55a6c4cc480697f4debe3e780dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3a2a1506d447779d809ff3bfc78151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13794 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 40\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"fr_nlp\": fr_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "val_dataset = val_dataset.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_dataset = test_dataset.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ee1ab18-4420-4309-b4aa-1bf9bb494e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'main personal exhibitions',\n",
       " 'fr': 'principales expositions personnelles',\n",
       " 'en_tokens': ['<sos>', 'main', 'personal', 'exhibitions', '<eos>'],\n",
       " 'fr_tokens': ['<sos>', 'principales', 'expositions', 'personnelles', '<eos>']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b83189d-35d5-445c-8765-e16036f87535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    train_dataset[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "fr_vocab = build_vocab_from_iterator(\n",
    "    train_dataset[\"fr_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad9fd9ed-837c-4ed0-aeb6-2550a803f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', 'the', 'in', 'of', 'and', 'was', 'a']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1ee3a37-4998-48c4-a8af-133a030e8195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', 'de', 'a', 'en', 'la', 'le', 'est']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b28c4e21-22be-42fc-b36e-3c3fa5921776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5f14985-75d8-4c66-955f-3ade284de109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22065, 27292)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab), len(fr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d82ebb20-1056-41ce-8ea2-2338e59dce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == fr_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == fr_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7e9a13f-be4c-478d-8bd4-edcbfb43b94d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Token The not found and default index is not set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m en_vocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchtext/vocab/vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[token]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Token The not found and default index is not set"
     ]
    }
   ],
   "source": [
    "en_vocab['The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0672db85-316b-49cc-9965-f521cf9e2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "fr_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62037a77-2878-463d-ac24-2f9bbb808220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab['The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78749614-4afe-4d39-a200-98f2b88735fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6fc597e-9efe-456a-9818-a19c0feab279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[44, 418, 11111, 2487, 621]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "en_vocab.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7efd029a-1822-4b51-be70-68a153625bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'watching', 'crime', 'shows']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b4051b3-523e-4e0d-b3e3-778480a1fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, fr_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    fr_ids = fr_vocab.lookup_indices(example[\"fr_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"fr_ids\": fr_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2259c4c9-c1a1-47d4-a8f3-43000c1d5edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03946d219b7d416fb33198f74c00930b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/110345 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218072ea457d43c4892936fb37d6979e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13793 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebebe3173a3e46f69cbeac3412cf3f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13794 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn_kwargs = {\"en_vocab\": en_vocab, \"fr_vocab\": fr_vocab}\n",
    "\n",
    "train_dataset = train_dataset.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "val_dataset = val_dataset.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_dataset = test_dataset.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0126392-63ea-48b4-a44c-b4460e95fb91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'main personal exhibitions',\n",
       " 'fr': 'principales expositions personnelles',\n",
       " 'en_tokens': ['<sos>', 'main', 'personal', 'exhibitions', '<eos>'],\n",
       " 'fr_tokens': ['<sos>', 'principales', 'expositions', 'personnelles', '<eos>'],\n",
       " 'en_ids': [2, 177, 200, 528, 3],\n",
       " 'fr_ids': [2, 430, 476, 1903, 3]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5472f0fa-ca58-49df-8225-a95feb78a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"fr_ids\"]\n",
    "\n",
    "train_dataset = train_dataset.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8a412cf-ae03-4b5e-8f91-5b19a5d82318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([  2, 177, 200, 528,   3]),\n",
       " 'fr_ids': tensor([   2,  430,  476, 1903,    3]),\n",
       " 'en': 'main personal exhibitions',\n",
       " 'fr': 'principales expositions personnelles',\n",
       " 'en_tokens': ['<sos>', 'main', 'personal', 'exhibitions', '<eos>'],\n",
       " 'fr_tokens': ['<sos>', 'principales', 'expositions', 'personnelles', '<eos>']}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1a6a4-9c12-4ef7-9479-fe8917f11ed4",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "11a0dc84-4302-4500-9c74-78e26189e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_fr_ids = [example[\"fr_ids\"] for example in batch]\n",
    "        en_lens = [example[\"en_ids\"].shape[0] for example in batch]\n",
    "        fr_lens = [example[\"fr_ids\"].shape[0] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_fr_ids = nn.utils.rnn.pad_sequence(batch_fr_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"fr_ids\": batch_fr_ids,\n",
    "            \"en_lens\": en_lens,\n",
    "            \"fr_lens\": fr_lens\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ba61c82b-6019-428a-92b6-23e775d323e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d37c284b-467d-4963-8535-8848023f4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_dataset, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(val_dataset, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_dataset, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7382b22-5517-4dd8-96e5-b613d2736f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15132e3e-6ec4-4ee3-98da-380436ecee87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cb4f4cb-2793-4f88-b6ae-cdaf2b985326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bafc0aa-8ed6-4e48-bb74-c67c1c3b8f48",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2cd78b8-6e7a-4a03-b50f-db99b4b020d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_lens):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, np.array(src_lens), enforce_sorted=False, batch_first=False)\n",
    "        packed_outputs, (hidden, cell) = self.rnn(packed)\n",
    "        # outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ec6bd65-52ad-4248-8d79-1437d807b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # context = [n layers, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output = [seq length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # cell = [n layers, batch size, hidden dim]\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aadbceed-85fc-4101-925a-b8683f6ed8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, src_lens, trg, trg_lens, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src, src_lens)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        # input = [batch size]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden and previous cell states\n",
    "            # receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, hidden dim]\n",
    "            # cell = [n layers, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689f030-ac73-4f1e-b234-7c08a04c6a13",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b37c761b-ae7e-4e8c-b674-972407363db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(fr_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6e9ce29-f95b-4df3-b40e-2cea2e665fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27292, 22065)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "aad77bee-231e-4a58-aff0-2e2dc55f40f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(27292, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(22065, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=22065, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6c26f1d8-c966-464c-8341-ea335be4c01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 31,311,153 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97c50989-40e5-4d91-be13-d2449961d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
    "# scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6977cfc-e8b5-4394-9e3a-68e3465a4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"fr_ids\"].to(device)\n",
    "        src_lens = batch[\"fr_lens\"]\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        trg_lens = batch[\"en_lens\"]\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, src_lens, trg, trg_lens, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e475dff0-21fb-489a-91ff-e81aba19719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"fr_ids\"].to(device)\n",
    "            src_lens = batch[\"fr_lens\"]\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            trg_lens = batch[\"en_lens\"]\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, src_lens, trg, trg_lens, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7c0aa914-961b-433f-814f-b9970fc12764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory '../models/wiki/2024-12-01' already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|███▎                                                              | 1/20 [04:01<1:16:24, 241.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.830 | Train PPL: 340.323\n",
      "\tValid Loss:   5.142 | Valid PPL: 170.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████▌                                                           | 2/20 [08:39<1:18:54, 263.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.958 | Train PPL: 142.254\n",
      "\tValid Loss:   4.718 | Valid PPL: 111.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████████▉                                                        | 3/20 [14:01<1:22:11, 290.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.431 | Train PPL:  84.055\n",
      "\tValid Loss:   4.486 | Valid PPL:  88.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████▏                                                    | 4/20 [20:16<1:26:13, 323.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.014 | Train PPL:  55.394\n",
      "\tValid Loss:   4.347 | Valid PPL:  77.275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|████████████████▌                                                 | 5/20 [27:05<1:28:33, 354.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   3.666 | Train PPL:  39.098\n",
      "\tValid Loss:   4.283 | Valid PPL:  72.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████████████▊                                              | 6/20 [34:14<1:28:37, 379.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   3.375 | Train PPL:  29.226\n",
      "\tValid Loss:   4.266 | Valid PPL:  71.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███████████████████████                                           | 7/20 [42:24<1:30:06, 415.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   3.132 | Train PPL:  22.923\n",
      "\tValid Loss:   4.254 | Valid PPL:  70.388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████████████████▍                                       | 8/20 [50:59<1:29:27, 447.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.917 | Train PPL:  18.487\n",
      "\tValid Loss:   4.260 | Valid PPL:  70.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████████████████████████████▊                                   | 9/20 [1:00:03<1:27:31, 477.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.738 | Train PPL:  15.458\n",
      "\tValid Loss:   4.286 | Valid PPL:  72.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████▌                               | 10/20 [1:09:23<1:23:49, 502.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.581 | Train PPL:  13.214\n",
      "\tValid Loss:   4.327 | Valid PPL:  75.720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████████████████████▋                            | 11/20 [1:18:51<1:18:25, 522.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.446 | Train PPL:  11.544\n",
      "\tValid Loss:   4.344 | Valid PPL:  76.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████▊                         | 12/20 [1:28:42<1:12:29, 543.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.336 | Train PPL:  10.341\n",
      "\tValid Loss:   4.395 | Valid PPL:  81.059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████▉                      | 13/20 [2:01:37<1:54:01, 977.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.234 | Train PPL:   9.341\n",
      "\tValid Loss:   4.429 | Valid PPL:  83.833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████                   | 14/20 [2:12:56<1:28:43, 887.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.147 | Train PPL:   8.563\n",
      "\tValid Loss:   4.470 | Valid PPL:  87.350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████▎               | 15/20 [2:24:24<1:08:56, 827.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.069 | Train PPL:   7.920\n",
      "\tValid Loss:   4.513 | Valid PPL:  91.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████             | 16/20 [2:36:03<52:33, 788.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.002 | Train PPL:   7.405\n",
      "\tValid Loss:   4.555 | Valid PPL:  95.130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|███████████████████████████████████████████████████████▎         | 17/20 [2:47:44<38:06, 762.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.949 | Train PPL:   7.023\n",
      "\tValid Loss:   4.577 | Valid PPL:  97.233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████▌      | 18/20 [2:59:40<24:56, 748.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.897 | Train PPL:   6.664\n",
      "\tValid Loss:   4.627 | Valid PPL: 102.226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████████████████████████████▊   | 19/20 [3:11:54<12:23, 743.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.845 | Train PPL:   6.327\n",
      "\tValid Loss:   4.665 | Valid PPL: 106.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 20/20 [3:24:18<00:00, 612.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.807 | Train PPL:   6.095\n",
      "\tValid Loss:   4.690 | Valid PPL: 108.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "model_dir = f'../models/wiki/{date}'\n",
    "# Create the directory\n",
    "try:\n",
    "    os.mkdir(model_dir)\n",
    "    print(f\"Directory '{model_dir}' created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{model_dir}' already exists.\")\n",
    "\n",
    "train_lossi = []\n",
    "val_lossi = []  \n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "\n",
    "    train_lossi.append(train_loss)\n",
    "    val_lossi.append(valid_loss)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), os.path.join(model_dir, f'mt_wiki_{train_loss:7.2f}_{valid_loss:7.2f}.pt'))\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f6d16c-254a-4943-abfa-1f80d580c977",
   "metadata": {},
   "source": [
    "### Evaluating on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9b062474-122f-4ba7-ad31-40c1642d39e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.257 | Test PPL:  70.567 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(model_dir, f'mt_wiki.pt')))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3529853-917c-4aeb-821b-8faae4088b46",
   "metadata": {},
   "source": [
    "### BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "489816d4-d19b-4be6-89b2-a20897500f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    fr_nlp,\n",
    "    en_vocab,\n",
    "    fr_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            tokens = [token.text for token in fr_nlp.tokenizer(sentence)]\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = fr_vocab.lookup_indices(tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        src_len = [tensor.shape[0]]\n",
    "        hidden, cell = model.encoder(tensor, src_len)\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        tokens = en_vocab.lookup_tokens(inputs)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8161c3a8-c0ed-4bbf-b3bf-70eecf88d178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('musiques nationales', 'national songs')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[0][\"fr\"]\n",
    "expected_translation = test_data[0][\"en\"]\n",
    "\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e338b1c8-758b-4646-ae86-435712b72762",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    fr_nlp,\n",
    "    en_vocab,\n",
    "    fr_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3494b57c-e64a-4213-aa08-71cad83b61af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'international', '<eos>']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "95016306-2816-4098-9f88-a6cad297b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Bonjour.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "398efc9f-102f-4337-a919-d8238bc5b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    fr_nlp,\n",
    "    en_vocab,\n",
    "    fr_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5df628b6-792f-4c3c-87ad-380b19a75378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', '<unk>', '<unk>', '<eos>']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad9d7364-9992-41a7-8375-93f58eacc62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 13794/13794 [04:03<00:00, 56.58it/s]\n"
     ]
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"fr\"],\n",
    "        model,\n",
    "        en_nlp,\n",
    "        fr_nlp,\n",
    "        en_vocab,\n",
    "        fr_vocab,\n",
    "        lower,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "    )\n",
    "    for example in tqdm.tqdm(test_dataset)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc0af41a-ae8c-4fe7-ab78-f6fecbcf8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "02c9ef00-ebe2-47f5-8acf-e92037144482",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "\n",
    "references = [[example[\"en\"]] for example in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6fbbabf8-a13b-49a2-9afa-074542db85df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('international', ['national songs'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0], references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "33c93115-0202-4440-b2fa-ca59d3aa8c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([  2, 111, 593,   3]),\n",
       " 'fr_ids': tensor([   2, 5012, 2367,    3]),\n",
       " 'en': 'national songs',\n",
       " 'fr': 'musiques nationales',\n",
       " 'en_tokens': ['<sos>', 'national', 'songs', '<eos>'],\n",
       " 'fr_tokens': ['<sos>', 'musiques', 'nationales', '<eos>']}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f5b4953-269e-4b8e-93bc-f8be471edf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_fn(nlp, lower):\n",
    "    def tokenizer_fn(s):\n",
    "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        return tokens\n",
    "\n",
    "    return tokenizer_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14f0711f-61b3-4749-88d4-82f81ba9864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8160d26c-83ec-4656-93f3-87c2b8d83605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['international'], ['national', 'songs'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_fn(predictions[0]), tokenizer_fn(references[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d02c0669-686a-46c4-a9cd-6507e7d33036",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bleu.compute(\n",
    "    predictions=predictions, references=references, tokenizer=tokenizer_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "60c7cb11-d5b8-4424-b328-e027b4c80365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.07782518866744352,\n",
       " 'precisions': [0.2571581801388434,\n",
       "  0.10498387459686492,\n",
       "  0.05091039770004792,\n",
       "  0.026690167443031602],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.186621647899026,\n",
       " 'translation_length': 67126,\n",
       " 'reference_length': 56569}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0166993f-1a2e-46ef-8f5e-549e2155def0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
