{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "172eeadc-b24d-4a95-9118-b356b13ad0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ba4f8b-5a60-418e-a3fe-cb6fff89d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2e4edcc-13b1-493f-b6aa-5fb87035ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import spacy\n",
    "import datasets\n",
    "import torchtext\n",
    "import tqdm\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16154ead-44d4-40bc-945c-effd6e5366d2",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6485e08a-e68b-47ee-84c7-6f21d4095b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36e81dcb-2772-446c-a5c0-801f25209986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(lang1, lang2):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('../data/tatoeba/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    # if reverse:\n",
    "    #     pairs = [list(reversed(p)) for p in pairs]\n",
    "    #     input_lang = Lang(lang2)\n",
    "    #     output_lang = Lang(lang1)\n",
    "    # else:\n",
    "    #     input_lang = Lang(lang1)\n",
    "    #     output_lang = Lang(lang2)\n",
    "\n",
    "    data = [{lang1: pair[0], lang2: pair[1]}for pair in pairs]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7f7890a-2ff6-4c2a-860a-adbbd2898325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "data = readData('en', 'fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06e7c943-7478-4919-a8a3-6d34eeddf77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'en': 'go', 'fr': 'va !'},\n",
       " {'en': 'run !', 'fr': 'cours !'},\n",
       " {'en': 'run !', 'fr': 'courez !'},\n",
       " {'en': 'wow !', 'fr': 'ca alors !'},\n",
       " {'en': 'fire !', 'fr': 'au feu !'},\n",
       " {'en': 'help !', 'fr': 'a l aide !'},\n",
       " {'en': 'jump', 'fr': 'saute'},\n",
       " {'en': 'stop !', 'fr': 'ca suffit !'},\n",
       " {'en': 'stop !', 'fr': 'stop !'},\n",
       " {'en': 'stop !', 'fr': 'arrete toi !'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d003fc8-9053-44c9-820c-ac87352acfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fc12cc8-497c-423d-8983-80f876e9a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splittng data\n",
    "n = len(data)\n",
    "n_train = int(0.8*n)\n",
    "n_val = int(0.9*n)\n",
    "\n",
    "train_data = data[:n_train]\n",
    "val_data = data[n_train:n_val]\n",
    "test_data = data[n_val:]\n",
    "\n",
    "# convert to Huggingface dataset\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "\n",
    "# Create the DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": val_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9979ef23-6b66-4691-9bf0-ec40bb997cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 108673\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 13584\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 13585\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1935ebe-e295-42c6-bee2-9602e920b81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'i ll leave it up to you', 'fr': 'je vous laisse la decision'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daf9b47d-9f45-40e7-96fb-fcb622490034",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "fr_nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d288c24-9e5d-41bc-8441-395eedd33361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What', 'a', 'lovely', 'day', 'it', 'is', 'today', '!']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"What a lovely day it is today!\"\n",
    "\n",
    "[token.text for token in en_nlp.tokenizer(string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05ae8750-8638-4c08-b352-4877982e4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, en_nlp, fr_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    fr_tokens = [token.text for token in fr_nlp.tokenizer(example[\"fr\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        fr_tokens = [token.lower() for token in fr_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    fr_tokens = [sos_token] + fr_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"fr_tokens\": fr_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef42e644-a5d6-4e81-abe9-a1876b552a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5949e4797a4239a98b78f8925701a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26ce9303b254e48940ac8b31ad81a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddde062bd9514273bf83702ad0fef34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13585 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 1_000\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\n",
    "    \"en_nlp\": en_nlp,\n",
    "    \"fr_nlp\": fr_nlp,\n",
    "    \"max_length\": max_length,\n",
    "    \"lower\": lower,\n",
    "    \"sos_token\": sos_token,\n",
    "    \"eos_token\": eos_token,\n",
    "}\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "val_dataset = val_dataset.map(tokenize_example, fn_kwargs=fn_kwargs)\n",
    "test_dataset = test_dataset.map(tokenize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ee1ab18-4420-4309-b4aa-1bf9bb494e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'i ll leave it up to you',\n",
       " 'fr': 'je vous laisse la decision',\n",
       " 'en_tokens': ['<sos>', 'i', 'll', 'leave', 'it', 'up', 'to', 'you', '<eos>'],\n",
       " 'fr_tokens': ['<sos>', 'je', 'vous', 'laisse', 'la', 'decision', '<eos>']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b83189d-35d5-445c-8765-e16036f87535",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "min_freq = 2\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [\n",
    "    unk_token,\n",
    "    pad_token,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "]\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(\n",
    "    train_dataset[\"en_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")\n",
    "\n",
    "fr_vocab = build_vocab_from_iterator(\n",
    "    train_dataset[\"fr_tokens\"],\n",
    "    min_freq=min_freq,\n",
    "    specials=special_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad9fd9ed-837c-4ed0-aeb6-2550a803f0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', 'i', 'you', 'to', 'the', '?', 'a']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1ee3a37-4998-48c4-a8af-133a030e8195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', '<sos>', '<eos>', 'je', 'a', 'de', 'pas', '?', 'vous']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_vocab.get_itos()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b28c4e21-22be-42fc-b36e-3c3fa5921776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5f14985-75d8-4c66-955f-3ade284de109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8146, 12220)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab), len(fr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d82ebb20-1056-41ce-8ea2-2338e59dce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == fr_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == fr_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7e9a13f-be4c-478d-8bd4-edcbfb43b94d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Token The not found and default index is not set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m en_vocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/torchtext/vocab/vocab.py:65\u001b[0m, in \u001b[0;36mVocab.__getitem__\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, token: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        token: The token used to lookup the corresponding index.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m        The index corresponding to the associated token.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[token]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Token The not found and default index is not set"
     ]
    }
   ],
   "source": [
    "en_vocab['The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0672db85-316b-49cc-9965-f521cf9e2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "fr_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62037a77-2878-463d-ac24-2f9bbb808220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab['The']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78749614-4afe-4d39-a200-98f2b88735fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.get_itos()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6fc597e-9efe-456a-9818-a19c0feab279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 133, 530, 1039, 3345]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]\n",
    "en_vocab.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7efd029a-1822-4b51-be70-68a153625bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'watching', 'crime', 'shows']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b4051b3-523e-4e0d-b3e3-778480a1fb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, fr_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    fr_ids = fr_vocab.lookup_indices(example[\"fr_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"fr_ids\": fr_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2259c4c9-c1a1-47d4-a8f3-43000c1d5edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3138ba23e1014e2c9dd3f6b28deb2db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/108673 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842550c03bf94c61bb17c8a02213f17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13584 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370e3b3926664501abf0cb84f89278f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13585 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fn_kwargs = {\"en_vocab\": en_vocab, \"fr_vocab\": fr_vocab}\n",
    "\n",
    "train_dataset = train_dataset.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "val_dataset = val_dataset.map(numericalize_example, fn_kwargs=fn_kwargs)\n",
    "test_dataset = test_dataset.map(numericalize_example, fn_kwargs=fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0126392-63ea-48b4-a44c-b4460e95fb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'i ll leave it up to you',\n",
       " 'fr': 'je vous laisse la decision',\n",
       " 'en_tokens': ['<sos>', 'i', 'll', 'leave', 'it', 'up', 'to', 'you', '<eos>'],\n",
       " 'fr_tokens': ['<sos>', 'je', 'vous', 'laisse', 'la', 'decision', '<eos>'],\n",
       " 'en_ids': [2, 4, 52, 163, 12, 63, 6, 5, 3],\n",
       " 'fr_ids': [2, 4, 9, 192, 13, 701, 3]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5472f0fa-ca58-49df-8225-a95feb78a872",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"fr_ids\"]\n",
    "\n",
    "train_dataset = train_dataset.with_format(\n",
    "    type=data_type, columns=format_columns, output_all_columns=True\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.with_format(\n",
    "    type=data_type,\n",
    "    columns=format_columns,\n",
    "    output_all_columns=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8a412cf-ae03-4b5e-8f91-5b19a5d82318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([  2,   4,  52, 163,  12,  63,   6,   5,   3]),\n",
       " 'fr_ids': tensor([  2,   4,   9, 192,  13, 701,   3]),\n",
       " 'en': 'i ll leave it up to you',\n",
       " 'fr': 'je vous laisse la decision',\n",
       " 'en_tokens': ['<sos>', 'i', 'll', 'leave', 'it', 'up', 'to', 'you', '<eos>'],\n",
       " 'fr_tokens': ['<sos>', 'je', 'vous', 'laisse', 'la', 'decision', '<eos>']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43dcda7f-23d9-402b-b3a3-482b5cf0a6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en_ids': tensor([  2,   4,  52, 163,  12,  63,   6,   5,   3]),\n",
       " 'fr_ids': tensor([  2,   4,   9, 192,  13, 701,   3]),\n",
       " 'en': 'i ll leave it up to you',\n",
       " 'fr': 'je vous laisse la decision',\n",
       " 'en_tokens': ['<sos>', 'i', 'll', 'leave', 'it', 'up', 'to', 'you', '<eos>'],\n",
       " 'fr_tokens': ['<sos>', 'je', 'vous', 'laisse', 'la', 'decision', '<eos>']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd1a6a4-9c12-4ef7-9479-fe8917f11ed4",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11a0dc84-4302-4500-9c74-78e26189e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_en_ids = [example[\"en_ids\"] for example in batch]\n",
    "        batch_fr_ids = [example[\"fr_ids\"] for example in batch]\n",
    "        en_lens = [example[\"en_ids\"].shape[0] for example in batch]\n",
    "        fr_lens = [example[\"fr_ids\"].shape[0] for example in batch]\n",
    "        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n",
    "        batch_fr_ids = nn.utils.rnn.pad_sequence(batch_fr_ids, padding_value=pad_index)\n",
    "        batch = {\n",
    "            \"en_ids\": batch_en_ids,\n",
    "            \"fr_ids\": batch_fr_ids,\n",
    "            \"en_lens\": en_lens,\n",
    "            \"fr_lens\": fr_lens\n",
    "        }\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba61c82b-6019-428a-92b6-23e775d323e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=collate_fn,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d37c284b-467d-4963-8535-8848023f4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data_loader = get_data_loader(train_dataset, batch_size, pad_index, shuffle=True)\n",
    "valid_data_loader = get_data_loader(val_dataset, batch_size, pad_index)\n",
    "test_data_loader = get_data_loader(test_dataset, batch_size, pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c7382b22-5517-4dd8-96e5-b613d2736f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bafc0aa-8ed6-4e48-bb74-c67c1c3b8f48",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2cd78b8-6e7a-4a03-b50f-db99b4b020d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_lens):\n",
    "        # src = [src length, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded = [src length, batch size, embedding dim]\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, np.array(src_lens), enforce_sorted=False, batch_first=False)\n",
    "        packed_outputs, (hidden, cell) = self.rnn(packed)\n",
    "        # outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        # outputs = [src length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # outputs are always from the top hidden layer\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ec6bd65-52ad-4248-8d79-1437d807b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embedding_dim, hidden_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.embedding = nn.Embedding(output_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input = [batch size]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # n directions in the decoder will both always be 1, therefore:\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # context = [n layers, batch size, hidden dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        # input = [1, batch size]\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # embedded = [1, batch size, embedding dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output = [seq length, batch size, hidden dim * n directions]\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # seq length and n directions will always be 1 in this decoder, therefore:\n",
    "        # output = [1, batch size, hidden dim]\n",
    "        # hidden = [n layers, batch size, hidden dim]\n",
    "        # cell = [n layers, batch size, hidden dim]\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        # prediction = [batch size, output dim]\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aadbceed-85fc-4101-925a-b8683f6ed8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        assert (\n",
    "            encoder.hidden_dim == decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            encoder.n_layers == decoder.n_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, src_lens, trg, trg_lens, teacher_forcing_ratio):\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        # teacher_forcing_ratio is probability to use teacher forcing\n",
    "        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_length = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        # tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_length, batch_size, trg_vocab_size).to(self.device)\n",
    "        # last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(src, src_lens)\n",
    "        # hidden = [n layers * n directions, batch size, hidden dim]\n",
    "        # cell = [n layers * n directions, batch size, hidden dim]\n",
    "        # first input to the decoder is the <sos> tokens\n",
    "        input = trg[0, :]\n",
    "        # input = [batch size]\n",
    "        for t in range(1, trg_length):\n",
    "            # insert input token embedding, previous hidden and previous cell states\n",
    "            # receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            # output = [batch size, output dim]\n",
    "            # hidden = [n layers, batch size, hidden dim]\n",
    "            # cell = [n layers, batch size, hidden dim]\n",
    "            # place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            # decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            # get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "            # if teacher forcing, use actual next token as next input\n",
    "            # if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            # input = [batch size]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689f030-ac73-4f1e-b234-7c08a04c6a13",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b37c761b-ae7e-4e8c-b674-972407363db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(fr_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 256\n",
    "decoder_embedding_dim = 256\n",
    "hidden_dim = 512\n",
    "n_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    encoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_layers,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aad77bee-231e-4a58-aff0-2e2dc55f40f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(12220, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(8146, 256)\n",
       "    (rnn): LSTM(256, 512, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=512, out_features=8146, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c26f1d8-c966-464c-8341-ea335be4c01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 16,749,010 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97c50989-40e5-4d91-be13-d2449961d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6977cfc-e8b5-4394-9e3a-68e3465a4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(\n",
    "    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n",
    "):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, batch in enumerate(data_loader):\n",
    "        src = batch[\"fr_ids\"].to(device)\n",
    "        src_lens = batch[\"fr_lens\"]\n",
    "        trg = batch[\"en_ids\"].to(device)\n",
    "        trg_lens = batch[\"en_lens\"]\n",
    "        # src = [src length, batch size]\n",
    "        # trg = [trg length, batch size]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, src_lens, trg, trg_lens, teacher_forcing_ratio)\n",
    "        # output = [trg length, batch size, trg vocab size]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "        trg = trg[1:].view(-1)\n",
    "        # trg = [(trg length - 1) * batch size]\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e475dff0-21fb-489a-91ff-e81aba19719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            src = batch[\"fr_ids\"].to(device)\n",
    "            src_lens = batch[\"fr_lens\"]\n",
    "            trg = batch[\"en_ids\"].to(device)\n",
    "            trg_lens = batch[\"en_lens\"]\n",
    "            # src = [src length, batch size]\n",
    "            # trg = [trg length, batch size]\n",
    "            output = model(src, src_lens, trg, trg_lens, 0)  # turn off teacher forcing\n",
    "            # output = [trg length, batch size, trg vocab size]\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            # output = [(trg length - 1) * batch size, trg vocab size]\n",
    "            trg = trg[1:].view(-1)\n",
    "            # trg = [(trg length - 1) * batch size]\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7c0aa914-961b-433f-814f-b9970fc12764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████▊                                                             | 1/10 [02:55<26:19, 175.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.425 | Train PPL:  83.501\n",
      "\tValid Loss:   3.916 | Valid PPL:  50.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████▌                                                      | 2/10 [06:14<25:12, 189.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   3.336 | Train PPL:  28.098\n",
      "\tValid Loss:   3.306 | Valid PPL:  27.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████▍                                               | 3/10 [10:02<24:08, 206.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.792 | Train PPL:  16.306\n",
      "\tValid Loss:   2.937 | Valid PPL:  18.867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████▏                                        | 4/10 [14:33<23:14, 232.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.420 | Train PPL:  11.248\n",
      "\tValid Loss:   2.721 | Valid PPL:  15.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████                                  | 5/10 [19:39<21:34, 258.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   2.151 | Train PPL:   8.590\n",
      "\tValid Loss:   2.572 | Valid PPL:  13.096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████▊                           | 6/10 [25:08<18:50, 282.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.959 | Train PPL:   7.096\n",
      "\tValid Loss:   2.465 | Valid PPL:  11.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████▌                    | 7/10 [32:02<16:16, 325.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.807 | Train PPL:   6.091\n",
      "\tValid Loss:   2.388 | Valid PPL:  10.887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████▍             | 8/10 [39:06<11:53, 356.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.685 | Train PPL:   5.395\n",
      "\tValid Loss:   2.351 | Valid PPL:  10.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████████████████████████████████████████████████████████▏      | 9/10 [46:44<06:28, 388.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.587 | Train PPL:   4.888\n",
      "\tValid Loss:   2.294 | Valid PPL:   9.919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 10/10 [54:26<00:00, 326.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   1.497 | Train PPL:   4.470\n",
      "\tValid Loss:   2.262 | Valid PPL:   9.601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "for epoch in tqdm.tqdm(range(n_epochs)):\n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        clip,\n",
    "        teacher_forcing_ratio,\n",
    "        device,\n",
    "    )\n",
    "    valid_loss = evaluate_fn(\n",
    "        model,\n",
    "        valid_data_loader,\n",
    "        criterion,\n",
    "        device,\n",
    "    )\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"tut1-model.pt\")\n",
    "    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f6d16c-254a-4943-abfa-1f80d580c977",
   "metadata": {},
   "source": [
    "### Evaluating on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b062474-122f-4ba7-ad31-40c1642d39e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 2.186 | Test PPL:   8.897 |\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"tut1-model.pt\"))\n",
    "\n",
    "test_loss = evaluate_fn(model, test_data_loader, criterion, device)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3529853-917c-4aeb-821b-8faae4088b46",
   "metadata": {},
   "source": [
    "### BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "489816d4-d19b-4be6-89b2-a20897500f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    fr_nlp,\n",
    "    en_vocab,\n",
    "    fr_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(sentence, str):\n",
    "            tokens = [token.text for token in fr_nlp.tokenizer(sentence)]\n",
    "        else:\n",
    "            tokens = [token for token in sentence]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        tokens = [sos_token] + tokens + [eos_token]\n",
    "        ids = fr_vocab.lookup_indices(tokens)\n",
    "        tensor = torch.LongTensor(ids).unsqueeze(-1).to(device)\n",
    "        src_len = [tensor.shape[0]]\n",
    "        hidden, cell = model.encoder(tensor, src_len)\n",
    "        inputs = en_vocab.lookup_indices([sos_token])\n",
    "        for _ in range(max_output_length):\n",
    "            inputs_tensor = torch.LongTensor([inputs[-1]]).to(device)\n",
    "            output, hidden, cell = model.decoder(inputs_tensor, hidden, cell)\n",
    "            predicted_token = output.argmax(-1).item()\n",
    "            inputs.append(predicted_token)\n",
    "            if predicted_token == en_vocab[eos_token]:\n",
    "                break\n",
    "        tokens = en_vocab.lookup_tokens(inputs)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8161c3a8-c0ed-4bbf-b3bf-70eecf88d178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('les dechets d usines polluent quelquefois nos rivieres',\n",
       " 'factory waste sometimes pollutes our rivers')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = test_data[0][\"fr\"]\n",
    "expected_translation = test_data[0][\"en\"]\n",
    "\n",
    "sentence, expected_translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e338b1c8-758b-4646-ae86-435712b72762",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    fr_nlp,\n",
    "    en_vocab,\n",
    "    fr_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3494b57c-e64a-4213-aa08-71cad83b61af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'prisons', '<unk>', '<unk>', '<unk>', 'their', '<eos>']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95016306-2816-4098-9f88-a6cad297b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Bonjour.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "398efc9f-102f-4337-a919-d8238bc5b25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_sentence(\n",
    "    sentence,\n",
    "    model,\n",
    "    en_nlp,\n",
    "    fr_nlp,\n",
    "    en_vocab,\n",
    "    fr_vocab,\n",
    "    lower,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5df628b6-792f-4c3c-87ad-380b19a75378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<sos>', 'let', 's', 'spoil', '<eos>']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d7364-9992-41a7-8375-93f58eacc62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███████████████████████▏                                       | 5007/13585 [01:21<02:31, 56.61it/s]"
     ]
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_sentence(\n",
    "        example[\"fr\"],\n",
    "        model,\n",
    "        en_nlp,\n",
    "        fr_nlp,\n",
    "        en_vocab,\n",
    "        fr_vocab,\n",
    "        lower,\n",
    "        sos_token,\n",
    "        eos_token,\n",
    "        device,\n",
    "    )\n",
    "    for example in tqdm.tqdm(test_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc0af41a-ae8c-4fe7-ab78-f6fecbcf8d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b82be95eef84990ab0d1fc80392812a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804f804541de431a9c61b4d1fa5c609a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeafb657f6394c3c961b71dddd6f1349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9ef00-ebe2-47f5-8acf-e92037144482",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "\n",
    "references = [[example[\"en\"]] for example in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbbabf8-a13b-49a2-9afa-074542db85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0], references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b4953-269e-4b8e-93bc-f8be471edf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_fn(nlp, lower):\n",
    "    def tokenizer_fn(s):\n",
    "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        return tokens\n",
    "\n",
    "    return tokenizer_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0711f-61b3-4749-88d4-82f81ba9864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160d26c-83ec-4656-93f3-87c2b8d83605",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_fn(predictions[0]), tokenizer_fn(references[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c0669-686a-46c4-a9cd-6507e7d33036",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bleu.compute(\n",
    "    predictions=predictions, references=references, tokenizer=tokenizer_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c7cb11-d5b8-4424-b328-e027b4c80365",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
